{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pafy\n",
    "import math\n",
    "import random \n",
    "import datetime\n",
    "import tensorflow as tf \n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=QmtSkq3DYko  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant =  27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the video frames \n",
    "Im_height, Im_width = 64, 64 \n",
    "\n",
    "# the number of frames fed to the model in one sequence\n",
    "sequence_length = 20\n",
    "\n",
    "dataset_dir = 'UCF50'\n",
    "\n",
    "# train on the following classes \n",
    "classes_list = [\"WalkingWithDog\",\"TaiChi\",\"Swing\",\"HorseRace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_exctraction(video_path):\n",
    "    '''\n",
    "    This function will extract the required frames from a video after resizing and normalizing them.\n",
    "\n",
    "    Args:\n",
    "        video_path : The path of the video in the disk, whose frames are to be exctracted \n",
    "    Returns:\n",
    "        frame_list : A list containing the resized and normalized frames of the video\n",
    "\n",
    "    '''\n",
    "\n",
    "    frame_list = []\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    frame_interval = max(int(video_frames_count/sequence_length),1)\n",
    "\n",
    "    for frame_counter in range(sequence_length):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * frame_interval)\n",
    "\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame,(Im_height,Im_width))\n",
    " \n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        frame_list.append(normalized_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    return frame_list \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    '''\n",
    "    This function will exctract the data of the selected classes and create the required dataset\n",
    "    Returns: \n",
    "        features:  A list containing the extracted frames of the videos. \n",
    "        labels:    A list containing the indexes of the classes\n",
    "    '''\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f\"Exctracting Data of class: {class_name}\")\n",
    "\n",
    "        files_list = os.listdir(os.path.join(dataset_dir, class_name))\n",
    "\n",
    "        for file_name in files_list:\n",
    "\n",
    "            video_file_path = os.path.join(dataset_dir, class_name, file_name)\n",
    "\n",
    "            frames =  frame_exctraction(video_file_path)\n",
    "\n",
    "            if len(frames) == sequence_length:\n",
    "\n",
    "                features.append(frames) \n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exctracting Data of class: WalkingWithDog\n",
      "Exctracting Data of class: TaiChi\n",
      "Exctracting Data of class: Swing\n",
      "Exctracting Data of class: HorseRace\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels into one-hot encoded vectors\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size=0.25, shuffle =True, random_state=seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convLSTM\n",
    "def create_convlstm():\n",
    "    model =  Sequential()\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 4,kernel_size=(3,3), activation='tanh', data_format=\"channels_last\",recurrent_dropout=0.2,return_sequences=True, \n",
    "                        input_shape=(sequence_length,Im_height,Im_width,3)))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 8,kernel_size=(3,3), activation='tanh', data_format=\"channels_last\",recurrent_dropout=0.2,return_sequences=True))\n",
    "\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format=\"channels_last\"))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 14,kernel_size=(3,3), activation='tanh', data_format=\"channels_last\",recurrent_dropout=0.2,return_sequences=True))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format=\"channels_last\"))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 16,kernel_size=(3,3), activation='tanh', data_format=\"channels_last\",recurrent_dropout=0.2,return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format=\"channels_last\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(len(classes_list), activation=\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 03:20:05.123454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.153623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.153732: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.154396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.154474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.154522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.812679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.812807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.812865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-28 03:20:05.812917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20985 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'channels_last' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convlstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_convlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mcreate_convlstm\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(TimeDistributed(Dropout(\u001b[38;5;241m0.2\u001b[39m)))\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(ConvLSTM2D(filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m,recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling3D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[43mchannels_last\u001b[49m))\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39madd(TimeDistributed(Dropout(\u001b[38;5;241m0.2\u001b[39m)))\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39madd(ConvLSTM2D(filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m,recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'channels_last' is not defined"
     ]
    }
   ],
   "source": [
    "convlstm_model = create_convlstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
